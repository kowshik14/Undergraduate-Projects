<<<<<<< HEAD
# An RNN-based Hybrid Model for Classification of Electrooculogram Signal for HCI

[![DOI](https://img.shields.io/badge/DOI-10.47839/ijc.22.3.3228-blue.svg)](http://dx.doi.org/10.47839/ijc.22.3.3228)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

    

> 📂 **Source code is [here](https://github.com/kowshik14/Undergraduate-Projects/tree/main/EOG-RNN-FeatureExtraction/src).**


## Abstract
In recent years, there has been a rise in the amount of research conducted in the field of human-computer interaction (HCI) employing electrooculography (EOG), which is a technology that is effectively and widely used to detect human eye activity. The use of EOG signals as a control signal for HCI is essential for understanding, characterizing, and classifying eye movements, which can be applied to a wide range of applications including virtual mouse and keyboard control, electric power wheelchairs, industrial assistive robots, and patient rehabilitation or communication purposes. In the field of HCI, EOG signals classification has continuously been performed to make the system more effective and reliable than ever. In this paper, a Recurrent neural network model is proposed for classifying eye movement directions utilizing several informative feature extraction methods and noise filtering. Our classification model is comprised of Gated Recurrent Unit (GRU) with a Bidirectional GRU followed by dense layers. The classifier is investigated to find a better classification performance of four directional eye movements: Up and Down for the vertical channel, along with Left and Right for the horizontal channel of EOG signals. The classifier achieved 99.77% and 99.74% accuracy for vertical and horizontal channels, respectively, which outperforms the compared state-of-the-art studies. The proposed classifier allows disabled people to make life-improving decisions using computers, achieving the highest classification performance for rehabilitation and other applications.

## Highlights

- **🔍 Research Focus**: Investigates human-computer interaction (HCI) using electrooculography (EOG) to detect eye activity.  
- **📱 Applications**: Utilizes EOG for virtual mouse control, electric wheelchairs, industrial robots, and patient rehabilitation.  
- **🧠 Classification Model**: Proposes a Recurrent Neural Network (RNN) model featuring Gated Recurrent Units (GRU) and Bidirectional GRU for classifying four eye movement directions (Up, Down, Left, Right).  
- **⚙️ Feature Engineering**: Implements time-domain feature extraction, signal denoising, and baseline drift mitigation to enhance signal quality and improve accuracy.  
- **📊 Performance**: Achieves 99.77% accuracy for vertical eye movements and 99.74% for horizontal eye movements, outperforming state-of-the-art studies.  
- **🌟 Impact**: Enhances HCI systems for disabled individuals, enabling improved decision-making and rehabilitation outcomes through more accurate eye movement classification.  

## Dataset Link

- [![EOG Dataset](https://img.shields.io/badge/EOG_Dataset-Available-darkgreen)](https://www.um.edu.mt/cbc/ourprojects/eyecon/eogdataset/)
- [![EOG Vertical Signal](https://img.shields.io/badge/EOG_Vertical_Signal-Available-darkgreen)](https://www.timeseriesclassification.com/description.php?Dataset=EOGVerticalSignal)
- [![EOG Horizontal Signal](https://img.shields.io/badge/EOG_Horizontal_Signal-Available-darkgreen)](https://www.timeseriesclassification.com/description.php?Dataset=EOGHorizontalSignal)

  
## Citation

If you find this work useful, please cite our paper:  
K. S. Roy and S. M. R. Islam, “An RNN-based Hybrid Model for Classification of Electrooculogram Signal for HCI”, IJC, vol. 22, no. 3, pp. 335-344, Oct. 2023. 

## Installation

To install, run the following command:

```bash
git clone https://github.com/kowshik14/Undergraduate-Projects/tree/main/EOG-RNN-FeatureExtraction
=======
# An RNN-based Hybrid Model for Classification of Electrooculogram Signal for HCI

[![DOI](https://img.shields.io/badge/DOI-10.47839/ijc.22.3.3228-blue.svg)](http://dx.doi.org/10.47839/ijc.22.3.3228)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

    

> 📂 **Source code is [here](https://github.com/kowshik14/Undergraduate-Projects/tree/main/EOG-RNN-FeatureExtraction/src).**


## Abstract
In recent years, there has been a rise in the amount of research conducted in the field of human-computer interaction (HCI) employing electrooculography (EOG), which is a technology that is effectively and widely used to detect human eye activity. The use of EOG signals as a control signal for HCI is essential for understanding, characterizing, and classifying eye movements, which can be applied to a wide range of applications including virtual mouse and keyboard control, electric power wheelchairs, industrial assistive robots, and patient rehabilitation or communication purposes. In the field of HCI, EOG signals classification has continuously been performed to make the system more effective and reliable than ever. In this paper, a Recurrent neural network model is proposed for classifying eye movement directions utilizing several informative feature extraction methods and noise filtering. Our classification model is comprised of Gated Recurrent Unit (GRU) with a Bidirectional GRU followed by dense layers. The classifier is investigated to find a better classification performance of four directional eye movements: Up and Down for the vertical channel, along with Left and Right for the horizontal channel of EOG signals. The classifier achieved 99.77% and 99.74% accuracy for vertical and horizontal channels, respectively, which outperforms the compared state-of-the-art studies. The proposed classifier allows disabled people to make life-improving decisions using computers, achieving the highest classification performance for rehabilitation and other applications.

## Highlights

- **🔍 Research Focus**: Investigates human-computer interaction (HCI) using electrooculography (EOG) to detect eye activity.  
- **📱 Applications**: Utilizes EOG for virtual mouse control, electric wheelchairs, industrial robots, and patient rehabilitation.  
- **🧠 Classification Model**: Proposes a Recurrent Neural Network (RNN) model featuring Gated Recurrent Units (GRU) and Bidirectional GRU for classifying four eye movement directions (Up, Down, Left, Right).  
- **⚙️ Feature Engineering**: Implements time-domain feature extraction, signal denoising, and baseline drift mitigation to enhance signal quality and improve accuracy.  
- **📊 Performance**: Achieves 99.77% accuracy for vertical eye movements and 99.74% for horizontal eye movements, outperforming state-of-the-art studies.  
- **🌟 Impact**: Enhances HCI systems for disabled individuals, enabling improved decision-making and rehabilitation outcomes through more accurate eye movement classification.  

## Dataset Link

- [![EOG Dataset](https://img.shields.io/badge/EOG_Dataset-Available-darkgreen)](https://www.um.edu.mt/cbc/ourprojects/eyecon/eogdataset/)
- [![EOG Vertical Signal](https://img.shields.io/badge/EOG_Vertical_Signal-Available-darkgreen)](https://www.timeseriesclassification.com/description.php?Dataset=EOGVerticalSignal)
- [![EOG Horizontal Signal](https://img.shields.io/badge/EOG_Horizontal_Signal-Available-darkgreen)](https://www.timeseriesclassification.com/description.php?Dataset=EOGHorizontalSignal)

  
## Citation

If you find this work useful, please cite our paper:  
K. S. Roy and S. M. R. Islam, “An RNN-based Hybrid Model for Classification of Electrooculogram Signal for HCI”, IJC, vol. 22, no. 3, pp. 335-344, Oct. 2023. 

## Installation

To install, run the following command:

```bash
git clone https://github.com/kowshik14/Undergraduate-Projects/tree/main/EOG-RNN-FeatureExtraction
>>>>>>> 0f0bd10 (added matlab and update README)
